# Third Generation Sequencing

!!! Warning
    Be sure to use the `ont` Codespace when initiating VM for this practical.
    Also - please use the correct conda environment for this practical:
    ```
    conda activate ont
    ```


## Introduction

In this session we are going to be looking at data generated by third-generation nanopore sequencing technology. Developed by Oxford Nanopore Technologies (ONT), these platforms, rather than the next-generation 'sequencing-by-synthesis approach', make use of an array of microscopic protein ‘pores’ set in in an electrically resistant membrane which guide strands of DNA or RNA through them. Each nanopore corresponds to its own electrode connected to a channel and sensor chip, which measures the electric current that flows through the nanopore. When a molecule passes through a nanopore, the current is disrupted to produce a characteristic ‘squiggle’. The squiggle is then decoded using basecalling algorithms to determine the DNA or RNA sequence in real time. Oxford Nanopore’s most popular platform is the MinION which is capable of generating single reads of over 4Mb.

![ngs1](../img/ngs1.gif)

The MinION is one of 5 scalable platforms developed by ONT. High-throughput applications such as the GridION and PromethION use an array of nanopore flowcells to produce between 5 to 48 times more data than the MinION alone – outputting up to 48 TB of data in one run. More downscaled solutions such as The Flongle and SmidgION use a smaller, single flowcell to generate data. The MinION is a highly portable sequencing platform, about the size of a large USB flash drive. This technology enables researchers to perform sequencing analyses almost anywhere, providing they have the correct equipment to prepare the DNA libraries and analyse the output data.

![ngs2](../img/ngs2.jpeg)

A complete sequencing run on the MinION platform can generate upwards to of 1TB of raw data, and downstream analyses require a significant amount of computing power, multicore high performance processors and large amounts of RAM. This poses a significant logistical challenge for researchers who want to take advantage of the platform’s portability aspect. Over recent years, the integration of GPUs (graphics processing units) has made it easier to analysis workflows.

![ngs3](../img/ngs3.png)

The long reads that are generated from nanopore are perfect for De novo assembly purposes, due to the way that they span repetitive regions and structural variants, making it easier to reconstruct genomes with fewer gaps and higher contiguity compared to short-read sequencing. So in this practical we will run through long read and hybrid assemblies to compare with our previous assemblies using just short reads.

## Activity Briefing



## Basecalling

Basecalling is performed with a tool called `dorado`. This tool is used to convert the raw signal data generated by the MinION into a sequence of nucleotides. The basecaller uses a neural network to predict the sequence of bases from the raw signal data. The output of the basecaller is a fastq file, which contains the basecalled sequence, as well as other information about the read, such as the quality scores of the basecalls. 

Basecalling required the use of advanced machine learning models, and can be computationally intensive. For this reason, basecalling is often performed on a high-performance computing cluster with a graphics processing unit. In this activity, we will use a smaller dataset to allow for the basecaller to work on our machines, and run quickly, just to get an idea of how the basecaller works.

![ngs4](../img/ngs4.gif)     ![ngs5](../img/ngs5.png)

```
cd ~/data/nanopore_activity/basecalling/pod5_pass/
```

!!! info
    Use the `ls` command to see what is inside this folder. This directory holds the POD5s that passed from the sequencing process that is done on the MinKNOW software provided with the sequencer. During a sequencing run, the MinKNOW software (or other ONT control software) records the raw electrical signals generated as DNA or RNA molecules pass through the nanopores. This raw signal data, along with metadata about the run, device, and reads, is then structured into Apache Arrow tables and packaged into the POD5 file format. The pod5_pass directory shows which of these signals passed the initial QC, but for basecalling we will use all the pod5s and further filter if needed later on.

## Basecalling: Dorado

We have our pod5's directly from the nanopore sequencer, now its time to basecall the data to get the fastq or bam files depending on the user input. To run dorado correctly, we need a few things

1. The actual sequencing data
2. The barcoding kit. Important to get right due to the signal interpretation from the model, and the specific barcoding sequences given to each model.
3. The basecalling model. The machine learning model to decode the nanopore sequencing data. You can learn more about the models here https://dorado-docs.readthedocs.io/en/latest/models/models/. But they essentially come in 3 different versions
- fast (the fastest and least accurate)
- hac (high accuracy)
- sup (super-accurate, the most accurate)
4. The sample sheet. Information about the samples you're running, must be in the correct format which you can see here https://dorado-docs.readthedocs.io/en/latest/barcoding/sample_sheet/

You will find all of these things in the dorado directory. 

First we move our pod5s into one directory

```
cd ..
mv */*.pod5 pod5s/
```

The basecaller also allows the option to provide a reference to do mapping using minimap2, but we will skip this for now and output a fastq using the `--emit-fastq` option.

Now, let's run Dorado on a small selection of our POD5 files for a quicker demonstration (expect around 5 minutes). Processing the full dataset would typically take approximately 20 minutes, as basecalling is computationally intensive.

```
dorado basecaller dna_r10.4.1_e8.2_400bps_fast@v4.1.0/ pod5s/ \
--min-qscore 7 \
--kit-name SQK-NBD114-24 \
--sample-sheet sample_sheet.csv \
--trim all \
--emit-fastq \
--output-dir dorado_out
```

Within our output directory we will have a fastq file, which we can then use to do further analysis. Here we have provided a better output from the basecaller using more pod5s to continue with downstream analysis.

## Basecalling: Quality Control

Before moving on to the analysis steps, it is important to gauge the quality of your sequencing output. There are numerous factors which dictate the quality of the output data, spanning between quality of the input material, library preparation to software and hardware failure. We will look at some important metrics produced by the sequencer which will give us a feel for how well the run went.

In order to get the run metrics in to a useful form, we will use pycoQC to produce a range of plots in a HTML output, which we will use to judge the quality of the sequencing run. We will run it on another output separate from the basecalling step you ran earlier, and instead from an actual basecalled run we have done already using all the data.

```
pycoQC -f ~/data/nanopore_activity/basecalling/fastq/sequencing_summary.txt -a ~/data/nanopore_activity/basecalling/bam/calls.sorted.bam -o pycoqc_results.html
```

You'll notice that the command failed with the following error:

```
module not found 'pysam'
```

This is because the `pysam` module is not installed in the `ont` conda environment. To install it, run the following command:

```
mamba install -c bioconda pysam
```

Now try re-running the `pycoQC` command

!!! info
    After executing the command you should find a file called 'pycoqc_results.html'. Open them up in the file manager or in the terminal (with the below command) and inspect some of the plots and see what you can find out. 

```
firefox ~/data/nanopore_activity/basecalling/fastq/pass/pycoqc_results.html
```

Before continuing, quit firefox by clicking the X in the top right corner of the web-browser window.

!!! question
    === "Question 1"
        Approximately how long did the sequencing run take?
    === "Answer 1"
        over 24 hours!

!!! question
    === "Question 2"
        What is the N50 of the passed reads (>Q7) for all basecalled reads in this run?
    === "Answer 2"
        N50 = 6700 bp

## Barcode and Adapter Trimming

Nanopore library preparation results in the addition of a sequencing adapter at each end of the fragment. Both the template and complement strands to be sequenced carry the motor protein which means both strands are able to translocate the nanopore. Barcodes are also be added during library prep to label and distinguish samples in multiplexed sequencing runs. For downstream analysis, it is important to remove both of these. For this we will use Chopper. This program processes all of the reads in our basecalled fastq file, and removes these adapter sequences and barcodes. Furthermore, the ligation library prep process can result in conjoined reads, meaning an adapter will be found in the middle of an extra-long read. [Chopper](https://github.com/wdecoster/chopper?tab=readme-ov-file) will identify these, split them and remove the adapters. 

Dorado does have the option to `--trim`, but due to the nature of nanopore being still developed, sometimes these adapters and barcodes can be left in the sequences still so its important to still run chopper just incase.

**Let's launch chopper and remove the adapters from the basecalled fastq file:**

```
gunzip -c  ~/data/nanopore_activity/basecalling/fastq/pass/calls.fastq.gz | chopper -q 10 -l 500 | gzip > ~/data/nanopore_activity/basecalling/fastq/pass/filtered_reads.fastq.gz
```

## Kraken QC

Another method of quality control is to check our reads for sequence contamination from other 'off-target' organisms. This is important in order to firstly, understand how effective your DNA extraction, enrichment and sequencing was. And secondly, to prevent anomalous reads from being incorporated in to assemblies.

Using our basecalled reads we will perform an analysis using Kraken. Kraken is a tool which sifts through each read in a .fastq file and crosschecks it against a database of microorganisms. The output is a taxonomic assignment of each read, enabling to identify if any contamination has occurred. In this case we will be looking for any reads which do not belong to our sample, which is salmonella.

**Let’s navigate to the kraken folder to begin the analysis:**

```
cd ~/data/nanopore_activity/kraken
```

**Type the following command in to the terminal to unleash the Kraken:**

```
kraken2 --db db --report kraken.report.txt --output kraken.output.txt filtered_reads.fastq.gz 
```

The `--db` flag specifies the database to use. In this case we are using a database with only bacterial sequences. The `--report` flag specifies the output file for the report, and the `--output` flag specifies the output file for the taxonomic assignments.

### Kraken Report

The report generated by Kraken is a tab-delimited file which contains a list of all the reads in the input file, and the taxonomic assignment of each read. The first column is the read ID, the second is the taxonomic ID, the third is the length of the read, and the fourth is the lowest common ancestor (LCA) of the taxonomic assignment. The LCA is the lowest taxonomic rank that all the taxonomic assignments share. The report is useful for identifying the taxonomic assignments of reads, and for identifying any contamination in the dataset.

### Kraken Output

The output generated by Kraken is a tab-delimited file which contains the taxonomic assignment of each read. The first column is the read ID, the second is the taxonomic ID, the third is the length of the read, and the fourth is the taxonomic assignment. The output is useful for identifying the taxonomic assignments of reads, and for identifying any contamination in the dataset.


### Visualising Kraken

Once we have run Kraken, we can visualise it with KronaTools. This creates a circular plot of what is inside your data.

```
ktImportTaxonomy -t 5 -m 3 -o krona.html kraken.report.txt
```

!!! info
    Similar to the pycoQC command, you will get a html output called 'krona.html'. Open them up in the file manager or in the terminal (with the below command) and inspect the circular plot.

```
firefox krona.html
```

![ngs6](../img/ngs6.png)

From the plot you'll notice that the sample is nearly completely clean of contaminants, and therefore does not need and further filtering.

## De novo Assembly

### long only

### hybrid



